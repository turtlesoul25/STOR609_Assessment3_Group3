---
title: "STOR-609 Presentation"
subtitle: |
  Reproducibility of Optimal Play for Pig(let)
  
  Group 3
author: 
    - Vlad Bercovici
    - Malcolm Connolly 
    - Rebekah Fearnhead
    - Niharika Peddinenikalva
format: pptx
transition: slide
incremental: true
theme: simple
---


## Summary of our findings

-   We believe we have managed to reproduce all figures from the original paper.
-   We found that the figures of winning percentages were different from those in the paper.

## Optimal Piglet play (Figure 2) {.smaller}

:::: {.columns} 
::: {.column width="40%"} 
- Each of the lines represents how the estimates for each of the win probabilities changes as iterations of the algorithm are performed.
- The win probability converges within the first $25$ iterations.
:::

::: {.column width="60%"}

![](./FIGURES/PIGLET_convergence.png){.lightbox}

:::

::::


## Optimal Pig play surface (Figure 3) {.smaller}

:::: {.columns} 
::: {.column width="37.5%"} 
- In the graph the boundary surface is shown between the states where rolling again is the optimal policy (in grey) and those where the optimal policy is to hold (transparent)
- We use the optimal policy obtained from value iteration to plot all states where rolling is the found to be the optimal policy.
:::

::: {.column width="62.5%"}
```{=html}
<iframe src="Figures/Roll_boundary_PIG_target_100_d6.html" width="100%" height="600px" style="border:none;"></iframe>
```
:::

::::


## Roll/Hold Boundary plot (Figure 4) {.smaller}

:::: {.columns} 
::: {.column width="40%"} 
- Figure 4 is a cross-section of figure 3.
- Figure 4 is easier to compare to the graph created with our results, as it is only in two dimensions.
- For lower values of player 1's score they want to roll while they have a turn total of up to. This value decreases until a player score of around at which point they wish to roll until they have won.
:::

::: {.column width="60%"}

![](./FIGURES/cross_sec_reachable_PIG_target_100_d6.png){.lightbox}
:::

::::

## Reachable states (Figure 5) {.smaller}

:::: {.columns} 
::: {.column width="40%"} 
- Figure 5 shows all the states that can be reached with a player following the optimal policy.
- There are $4$ gaps in the reachable states, as in the paper.
- An optimal player with score of $0$ will never hold before reaching a turn total less than $21$ which can be seen in the graph.
:::

::: {.column width="60%"}
```{=html}
<iframe src="Figures/Reachable_states_PIG_target_100_d6.html" width="100%" height="600px" style="border:none;"></iframe>
```
:::

::::


## Reachable states with optimal rolling (Figure 6) {.smaller}

:::: {.columns} 
::: {.column width="40%"} 
- Figure 6 is similar to Figure 3 but instead of showing the optimal policy for all states, it just shows the optimal policy for the states that are reachable as found in Figure 5.
- This is created by looking at the reachable states found for Figure 5, showing only those states at which the optimal policy is to roll.

:::

::: {.column width="60%"}
```{=html}
<iframe src="Figures/Reachable_states_opt_roll_PIG_target_100_d6.html" width="100%" height="600px" style="border:none;"></iframe>
```
:::

::::



## Winning probability contours (Figure 7) {.smaller}

:::: {.columns} 
::: {.column width="40%"} 
- Figure 7 shows contours of different winning probabilities computed from the optimal policy.
- We draw a contour wherein the states have a win probability that is within a threshold $t$ from the desired probability, e.g. in the interval $x\% \pm t$.
- The thresholds selected were manually selected for each of the $4$ probabilities in order to yield smooth surfaces.
:::

::: {.column width="60%"}
```{=html}
<iframe src="Figures/contours_PIG_target_100_d6.html" width="100%" height="600px" style="border:none;"></iframe>
```
:::

::::



## 5 Rs of Neller and Cresser
Replicability refers to when algorithm or solution can be recoded by someone else. 

-  The methodology as described in the paper is not replicable, in particular the description of Value Iteration algorithm. 

-  We were able to replicate their figures and recoded their implementation from their description. 

- Java code authors supplied for piglet was re-runnable and repeatable.

- No code means not all Rs applicable.


## Our work and the 5Rs (I)

-   Our code is re-runnable by a third party, and we provide a package. 
-   Our results are repeatable, as we obtain the same optimal policy after convergence, and we specify iterations.
-   Our solution is reproducible, robust to different versions of python in future utilising sets, dictionaries and other base pythonic structures.
-   Our results are replicable, we explain methodology in detail, and provide pseudocode.


## Our work and the 5Rs (II)

-   Our code is reusable for simple extensions of Pig such as goal-n-Pig, and routinely adaptable to different versions of Pig with equations (e.g. 2 6-sided dice losing with snake eyes, changes in input equation).
-   Further Piglet could be extended to have different goal numbers (twiglet, triglet, quiglet?).
-   Did not explore other extensions mentioned in paper such as jeopardy approach games.

